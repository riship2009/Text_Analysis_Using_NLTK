{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['austen-emma.txt',\n",
       " 'austen-persuasion.txt',\n",
       " 'austen-sense.txt',\n",
       " 'bible-kjv.txt',\n",
       " 'blake-poems.txt',\n",
       " 'bryant-stories.txt',\n",
       " 'burgess-busterbrown.txt',\n",
       " 'carroll-alice.txt',\n",
       " 'chesterton-ball.txt',\n",
       " 'chesterton-brown.txt',\n",
       " 'chesterton-thursday.txt',\n",
       " 'edgeworth-parents.txt',\n",
       " 'melville-moby_dick.txt',\n",
       " 'milton-paradise.txt',\n",
       " 'shakespeare-caesar.txt',\n",
       " 'shakespeare-hamlet.txt',\n",
       " 'shakespeare-macbeth.txt',\n",
       " 'whitman-leaves.txt']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import gutenberg\n",
    "gutenberg.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           can  could    may  might   will  would should \n",
      "        austen-emma.txt    270    825    213    322    559    815    366 \n",
      "  austen-persuasion.txt    100    444     87    166    162    351    185 \n",
      "       austen-sense.txt    206    568    169    215    354    507    228 \n",
      "          bible-kjv.txt    213    165   1024    475   3807    443    768 \n",
      "        blake-poems.txt     20      3      5      2      3      3      6 \n",
      "     bryant-stories.txt     75    154     18     23    144    110     38 \n",
      "burgess-busterbrown.txt     23     56      3     17     19     46     13 \n",
      "      carroll-alice.txt     57     73     11     28     24     70     27 \n",
      "    chesterton-ball.txt    131    117     90     69    198    139     75 \n",
      "   chesterton-brown.txt    126    170     47     71    111    132     56 \n",
      "chesterton-thursday.txt    117    148     56     71    109    116     54 \n",
      "  edgeworth-parents.txt    340    420    160    127    517    503    271 \n",
      " melville-moby_dick.txt    220    215    230    183    379    421    181 \n",
      "    milton-paradise.txt    107     62    116     98    161     49     55 \n",
      " shakespeare-caesar.txt     16     18     35     12    129     40     38 \n",
      " shakespeare-hamlet.txt     33     26     56     28    131     60     52 \n",
      "shakespeare-macbeth.txt     21     15     30      5     62     42     41 \n",
      "     whitman-leaves.txt     88     49     85     26    261     85     42 \n"
     ]
    }
   ],
   "source": [
    "cfd = nltk.ConditionalFreqDist(\n",
    "          (texts, word)\n",
    "           for texts in gutenberg.fileids()\n",
    "           for word in gutenberg.words(fileids=texts))\n",
    "modals = ['can', 'could', 'may', 'might', 'will','would','should']\n",
    "modal_dist = cfd.tabulate(conditions=texts, samples=modals)\n",
    "modal_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 10 of 837 matches:\n",
      "ry scheme of hers -- one to whom she could speak every thought as it arose , an\n",
      "who had such an affection for her as could never find fault . How was she to be\n",
      "but he was no companion for her . He could not meet her in conversation , ratio\n",
      "and his amiable temper , his talents could not have recommended him at any time\n",
      "y civil , but not one among them who could be accepted in lieu of Miss Taylor f\n",
      "t was a melancholy change ; and Emma could not but sigh over it , and wish for \n",
      " his own daughter ' s marrying , nor could ever speak of her but with compassio\n",
      "er able to suppose that other people could feel differently from himself , he w\n",
      "led and chatted as cheerfully as she could , to keep him from such thoughts ; b\n",
      "ar ? Randalls is such a distance . I could not walk half so far .\" \" No , papa \n"
     ]
    }
   ],
   "source": [
    "emma = nltk.Text(nltk.corpus.gutenberg.words('austen-emma.txt'))\n",
    "emma.concordance(\"could\",lines=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 6 of 6 matches:\n",
      "y father sold me while yet my tongue Could scarcely cry \" Weep ! weep ! weep ! \n",
      " presse With feet of weary woe ; She could no further go . In his arms he bore \n",
      "he night , What immortal hand or eye Could Frame thy fearful symmetry ? In what\n",
      "ire ? And what shoulder and what art Could twist the sinews of thy heart ? And \n",
      "ke somebody poor , And Mercy no more could be If all were as happy as we . And \n",
      "st holy mystery .\" The weeping child could not be heard , The weeping parents w\n"
     ]
    }
   ],
   "source": [
    "blake = nltk.Text(nltk.corpus.gutenberg.words('blake-poems.txt'))\n",
    "blake.concordance(\"could\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 6 of 1027 matches:\n",
      "eature that hath life , and fowl that may fly above the earth in the open firma\n",
      " the woman said unto the serpent , We may eat of the fruit of the trees of the \n",
      "t creepeth upon the earth ; that they may breed abundantly in the earth , and b\n",
      "ud ; and I will look upon it , that I may remember the everlasting covenant bet\n",
      "ild us a city and a tower , whose top may reach unto heaven ; and let us make u\n",
      "e confound their language , that they may not understand one another ' s speech\n"
     ]
    }
   ],
   "source": [
    "bible = nltk.Text(nltk.corpus.gutenberg.words('bible-kjv.txt'))\n",
    "bible.concordance(\"may\",lines=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 3 of 3 matches:\n",
      "here he was sitting . Now Buster Bear may be big and clumsy looking , but there\n",
      "ed Little Joe . \" Chug - a - rum ! He may be a bully , because great big people\n",
      "ve an idea that something interesting may happen if Buster doesn ' t change his\n"
     ]
    }
   ],
   "source": [
    "burgess = nltk.Text(nltk.corpus.gutenberg.words('burgess-busterbrown.txt'))\n",
    "burgess.concordance(\"may\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import inaugural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the words from inaugural corpus\n",
    "all_words = nltk.corpus.inaugural.words(nltk.corpus.inaugural.fileids())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total =  22917\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['citizens',\n",
       " 'representatives',\n",
       " 'vicissitudes',\n",
       " 'incident',\n",
       " 'anxieties',\n",
       " 'notification',\n",
       " 'transmitted',\n",
       " 'received']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "big_words = ([w.lower() \n",
    "              for w in all_words \n",
    "              if len(w) > 7])\n",
    "\n",
    "print(\"total = \",len(big_words))\n",
    "big_words[0:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('government', 600),\n",
       " ('citizens', 247),\n",
       " ('constitution', 206),\n",
       " ('american', 163),\n",
       " ('national', 157),\n",
       " ('congress', 130),\n",
       " ('interests', 115),\n",
       " ('political', 106),\n",
       " ('executive', 97),\n",
       " ('principles', 96)]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import FreqDist\n",
    "f_dist = FreqDist(big_words) # To get the frequency distribution in descending order\n",
    "top10_freq = f_dist.most_common(10)  # To the 10 most commonly used words\n",
    "top10_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word:  government\n",
      "Synonymns: \n",
      "  ['government', 'authorities', 'regime']\n",
      "  ['government', 'governing', 'governance', 'government_activity', 'administration']\n",
      "  ['government']\n",
      "  ['politics', 'political_science', 'government']\n",
      "\n",
      " -------------------------------------------------------------------------------------- \n",
      "\n",
      "Word:  citizens\n",
      "Synonymns: \n",
      "  ['citizen']\n",
      "\n",
      " -------------------------------------------------------------------------------------- \n",
      "\n",
      "Word:  constitution\n",
      "Synonymns: \n",
      "  ['fundamental_law', 'organic_law', 'constitution']\n",
      "  ['constitution', 'establishment', 'formation', 'organization', 'organisation']\n",
      "  ['United_States_Constitution', 'U.S._Constitution', 'US_Constitution', 'Constitution', 'Constitution_of_the_United_States']\n",
      "  ['constitution', 'composition', 'physical_composition', 'makeup', 'make-up']\n",
      "  ['Constitution', 'Old_Ironsides']\n",
      "\n",
      " -------------------------------------------------------------------------------------- \n",
      "\n",
      "Word:  american\n",
      "Synonymns: \n",
      "  ['American']\n",
      "  ['American_English', 'American_language', 'American']\n",
      "  ['American']\n",
      "  ['American']\n",
      "  ['American']\n",
      "\n",
      " -------------------------------------------------------------------------------------- \n",
      "\n",
      "Word:  national\n",
      "Synonymns: \n",
      "  ['national', 'subject']\n",
      "  ['national']\n",
      "  ['national']\n",
      "  ['national']\n",
      "  ['national']\n",
      "  ['home', 'interior', 'internal', 'national']\n",
      "  ['national']\n",
      "  ['national']\n",
      "\n",
      " -------------------------------------------------------------------------------------- \n",
      "\n",
      "Word:  congress\n",
      "Synonymns: \n",
      "  ['Congress', 'United_States_Congress', 'U.S._Congress', 'US_Congress']\n",
      "  ['congress']\n",
      "  ['congress']\n",
      "  ['sexual_intercourse', 'intercourse', 'sex_act', 'copulation', 'coitus', 'coition', 'sexual_congress', 'congress', 'sexual_relation', 'relation', 'carnal_knowledge']\n",
      "\n",
      " -------------------------------------------------------------------------------------- \n",
      "\n",
      "Word:  interests\n",
      "Synonymns: \n",
      "  ['interest', 'involvement']\n",
      "  ['sake', 'interest']\n",
      "  ['interest', 'interestingness']\n",
      "  ['interest']\n",
      "  ['interest', 'stake']\n",
      "  ['interest', 'interest_group']\n",
      "  ['pastime', 'interest', 'pursuit']\n",
      "  ['interest']\n",
      "  ['concern', 'interest', 'occupy', 'worry']\n",
      "  ['matter_to', 'interest']\n",
      "\n",
      " -------------------------------------------------------------------------------------- \n",
      "\n",
      "Word:  political\n",
      "Synonymns: \n",
      "  ['political']\n",
      "  ['political']\n",
      "  ['political']\n",
      "\n",
      " -------------------------------------------------------------------------------------- \n",
      "\n",
      "Word:  executive\n",
      "Synonymns: \n",
      "  ['executive', 'executive_director']\n",
      "  ['executive']\n",
      "  ['administrator', 'executive']\n",
      "  ['executive']\n",
      "\n",
      " -------------------------------------------------------------------------------------- \n",
      "\n",
      "Word:  principles\n",
      "Synonymns: \n",
      "  ['principle', 'rule']\n",
      "  ['principle']\n",
      "  ['principle']\n",
      "  ['principle', 'rule']\n",
      "  ['principle', 'precept']\n",
      "  ['rationale', 'principle']\n",
      "\n",
      " -------------------------------------------------------------------------------------- \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "for i in top10_freq:\n",
    "    \n",
    "    print(\"Word: \", i[0])\n",
    "    \n",
    "    count=0\n",
    "    \n",
    "    print(\"Synonymns: \")\n",
    "    for j in wn.synsets(i[0]):\n",
    "        print(\" \",j.lemma_names())\n",
    "        count+=len(j.lemma_names())\n",
    "        \n",
    "    print(\"\\n -------------------------------------------------------------------------------------- \\n\")\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word:  government \n",
      "\n",
      "Hyponyms: \n",
      "\n",
      "  [Synset('ancien_regime.n.01'), Synset('authoritarian_state.n.01'), Synset('bureaucracy.n.02'), Synset('court.n.03'), Synset('downing_street.n.02'), Synset('empire.n.02'), Synset('federal_government.n.01'), Synset('government-in-exile.n.01'), Synset('local_government.n.01'), Synset('military_government.n.01'), Synset('palace.n.02'), Synset('papacy.n.01'), Synset('puppet_government.n.01'), Synset('state.n.03'), Synset('state_government.n.01'), Synset('totalitarian_state.n.01')]\n",
      "  [Synset('legislation.n.02'), Synset('misgovernment.n.01'), Synset('trust_busting.n.01')]\n",
      "  []\n",
      "  [Synset('geopolitics.n.01'), Synset('realpolitik.n.01')]\n",
      "\n",
      "--------------------------------------------------------------------------------------\n",
      "\n",
      "Word:  citizens \n",
      "\n",
      "Hyponyms: \n",
      "\n",
      "  [Synset('active_citizen.n.01'), Synset('civilian.n.01'), Synset('freeman.n.01'), Synset('private_citizen.n.01'), Synset('repatriate.n.01'), Synset('thane.n.02'), Synset('voter.n.01')]\n",
      "\n",
      "--------------------------------------------------------------------------------------\n",
      "\n",
      "Word:  constitution \n",
      "\n",
      "Hyponyms: \n",
      "\n",
      "  []\n",
      "  [Synset('collectivization.n.01'), Synset('colonization.n.01'), Synset('communization.n.02'), Synset('federation.n.03'), Synset('unionization.n.01')]\n",
      "  []\n",
      "  [Synset('genotype.n.02'), Synset('karyotype.n.01'), Synset('phenotype.n.01'), Synset('structure.n.02'), Synset('texture.n.05')]\n",
      "  []\n",
      "\n",
      "--------------------------------------------------------------------------------------\n",
      "\n",
      "Word:  american \n",
      "\n",
      "Hyponyms: \n",
      "\n",
      "  [Synset('african-american.n.01'), Synset('alabaman.n.01'), Synset('alaskan.n.01'), Synset('anglo-american.n.01'), Synset('appalachian.n.01'), Synset('arizonan.n.01'), Synset('arkansan.n.01'), Synset('asian_american.n.01'), Synset('bay_stater.n.01'), Synset('bostonian.n.01'), Synset('californian.n.01'), Synset('carolinian.n.01'), Synset('coloradan.n.01'), Synset('connecticuter.n.01'), Synset('creole.n.02'), Synset('delawarean.n.01'), Synset('floridian.n.01'), Synset('franco-american.n.01'), Synset('georgian.n.01'), Synset('german_american.n.01'), Synset('hawaiian.n.02'), Synset('idahoan.n.01'), Synset('illinoisan.n.01'), Synset('indianan.n.01'), Synset('iowan.n.01'), Synset('kansan.n.01'), Synset('kentuckian.n.01'), Synset('louisianan.n.01'), Synset('mainer.n.01'), Synset('marylander.n.01'), Synset('michigander.n.01'), Synset('minnesotan.n.01'), Synset('mississippian.n.02'), Synset('missourian.n.01'), Synset('montanan.n.01'), Synset('nebraskan.n.01'), Synset('nevadan.n.01'), Synset('new_englander.n.01'), Synset('new_hampshirite.n.01'), Synset('new_jerseyan.n.01'), Synset('new_mexican.n.01'), Synset('new_yorker.n.01'), Synset('nisei.n.01'), Synset('north_carolinian.n.01'), Synset('north_dakotan.n.01'), Synset('ohioan.n.01'), Synset('oklahoman.n.01'), Synset('oregonian.n.01'), Synset('pennsylvanian.n.02'), Synset('puerto_rican.n.01'), Synset('rhode_islander.n.01'), Synset('south_carolinian.n.01'), Synset('south_dakotan.n.01'), Synset('southerner.n.01'), Synset('spanish_american.n.01'), Synset('tennessean.n.01'), Synset('texan.n.01'), Synset('tory.n.01'), Synset('utahan.n.01'), Synset('vermonter.n.01'), Synset('virginian.n.01'), Synset('washingtonian.n.01'), Synset('washingtonian.n.02'), Synset('west_virginian.n.01'), Synset('wisconsinite.n.01'), Synset('wyomingite.n.01'), Synset('yankee.n.01'), Synset('yankee.n.03')]\n",
      "  [Synset('african_american_vernacular_english.n.01')]\n",
      "  [Synset('creole.n.01'), Synset('latin_american.n.01'), Synset('mesoamerican.n.01'), Synset('north_american.n.01'), Synset('south_american.n.01'), Synset('west_indian.n.01')]\n",
      "  []\n",
      "  []\n",
      "\n",
      "--------------------------------------------------------------------------------------\n",
      "\n",
      "Word:  national \n",
      "\n",
      "Hyponyms: \n",
      "\n",
      "  [Synset('citizen.n.01'), Synset('compatriot.n.01'), Synset('patriot.n.01')]\n",
      "  []\n",
      "  []\n",
      "  []\n",
      "  []\n",
      "  []\n",
      "  []\n",
      "  []\n",
      "\n",
      "--------------------------------------------------------------------------------------\n",
      "\n",
      "Word:  congress \n",
      "\n",
      "Hyponyms: \n",
      "\n",
      "  []\n",
      "  [Synset('continental_congress.n.01')]\n",
      "  []\n",
      "  [Synset('defloration.n.02'), Synset('fuck.n.01'), Synset('hank_panky.n.01'), Synset('penetration.n.06'), Synset('unlawful_carnal_knowledge.n.01')]\n",
      "\n",
      "--------------------------------------------------------------------------------------\n",
      "\n",
      "Word:  interests \n",
      "\n",
      "Hyponyms: \n",
      "\n",
      "  [Synset('concern.n.01'), Synset('enthusiasm.n.03')]\n",
      "  [Synset('behalf.n.02')]\n",
      "  [Synset('charisma.n.01'), Synset('color.n.02'), Synset('newsworthiness.n.01'), Synset('shrillness.n.01'), Synset('topicality.n.01')]\n",
      "  [Synset('compound_interest.n.01'), Synset('simple_interest.n.01')]\n",
      "  [Synset('controlling_interest.n.01'), Synset('equity.n.02'), Synset('fee.n.02'), Synset('grubstake.n.01'), Synset('insurable_interest.n.01'), Synset('reversion.n.01'), Synset('right.n.08'), Synset('security_interest.n.01'), Synset('terminable_interest.n.01'), Synset('undivided_interest.n.01'), Synset('vested_interest.n.01')]\n",
      "  [Synset('special_interest.n.01'), Synset('vested_interest.n.02')]\n",
      "  [Synset('avocation.n.01')]\n",
      "  [Synset('absorb.v.09'), Synset('fascinate.v.02')]\n",
      "  []\n",
      "  [Synset('intrigue.v.01')]\n",
      "\n",
      "--------------------------------------------------------------------------------------\n",
      "\n",
      "Word:  political \n",
      "\n",
      "Hyponyms: \n",
      "\n",
      "  []\n",
      "  []\n",
      "  []\n",
      "\n",
      "--------------------------------------------------------------------------------------\n",
      "\n",
      "Word:  executive \n",
      "\n",
      "Hyponyms: \n",
      "\n",
      "  [Synset('corporate_executive.n.01'), Synset('minister.n.02'), Synset('rainmaker.n.01'), Synset('surgeon_general.n.01'), Synset('vice_president.n.01')]\n",
      "  [Synset('bush_administration.n.01'), Synset('bush_administration.n.02'), Synset('carter_administration.n.01'), Synset('clinton_administration.n.01'), Synset('reagan_administration.n.01')]\n",
      "  [Synset('commissioner.n.01'), Synset('director_of_central_intelligence.n.01'), Synset('prefect.n.01'), Synset('secretary_general.n.01'), Synset('triumvir.n.01')]\n",
      "  []\n",
      "\n",
      "--------------------------------------------------------------------------------------\n",
      "\n",
      "Word:  principles \n",
      "\n",
      "Hyponyms: \n",
      "\n",
      "  [Synset('feng_shui.n.01'), Synset('pillar.n.01'), Synset('yang.n.01'), Synset('yin.n.01')]\n",
      "  [Synset('accounting_principle.n.01'), Synset('chivalry.n.02'), Synset('ethic.n.01'), Synset('hellenism.n.01'), Synset('legal_principle.n.01'), Synset('scruple.n.03')]\n",
      "  [Synset('conservation.n.03'), Synset('dictate.n.02'), Synset('fundamentals.n.01'), Synset('insurrectionism.n.01'), Synset('logic.n.03'), Synset('pleasure_principle.n.01'), Synset('reality_principle.n.01'), Synset('tao.n.02')]\n",
      "  [Synset('gestalt_law_of_organization.n.01'), Synset('gresham's_law.n.01'), Synset('le_chatelier's_principle.n.01'), Synset('localization_of_function.n.01'), Synset('mass-action_principle.n.01'), Synset('mass-energy_equivalence.n.01'), Synset('naegele's_rule.n.01'), Synset('occam's_razor.n.01'), Synset('principle_of_equivalence.n.01'), Synset('principle_of_liquid_displacement.n.01'), Synset('principle_of_superposition.n.01'), Synset('principle_of_superposition.n.02')]\n",
      "  [Synset('caveat_emptor.n.01'), Synset('higher_law.n.01'), Synset('hypothetical_imperative.n.01'), Synset('moral_principle.n.02')]\n",
      "  [Synset('dialectics.n.01')]\n",
      "\n",
      "--------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in top10_freq:\n",
    "    \n",
    "    print(\"Word: \", i[0],\"\\n\")\n",
    "    \n",
    "    count=0\n",
    "    \n",
    "    print(\"Hyponyms: \\n\")\n",
    "    for j in wn.synsets(i[0]):\n",
    "        print(\" \",j.hyponyms())\n",
    "        count+=len(j.hyponyms())\n",
    "        \n",
    "    print(\"\\n--------------------------------------------------------------------------------------\\n\")\n",
    "     "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
